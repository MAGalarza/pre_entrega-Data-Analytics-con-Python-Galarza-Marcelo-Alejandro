{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPb8frOLqAg+i4UIHZGgMbD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Pre-Entrega de Proyecto\n","## Etapa 1: Recopilaci√≥n y Preparaci√≥n de Datos (Clases 1 a 4)"],"metadata":{"id":"cZ8DzzkBpkbM"}},{"cell_type":"markdown","source":["###1- Crear un documento en Google Colaboratory y cargar los sets de datos como DataFrames."],"metadata":{"id":"ZOQNfdR6p4bw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"af32VJsFUPBX"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","source":["*   Pandas: es una de las bibliotecas m√°s utilizadas para la manipulaci√≥n y el an√°lisis de datos en Python. Proporciona estructuras de datos flexibles como DataFrame y Series, que permiten almacenar y manipular datos en forma tabular, similar a una hoja de c√°lculo. Pandas ofrece herramientas eficientes para la lectura y escritura de datos, filtrado, agrupamiento, y tratamiento de datos faltantes, facilitando el an√°lisis exploratorio de datos.\n","*   NumPy: es fundamental para el c√°lculo num√©rico en Python. Proporciona un objeto de matriz multidimensional, llamado ndarray, que permite realizar operaciones matem√°ticas y estad√≠sticas de manera eficiente. NumPy es esencial para el manejo de datos num√©ricos, y muchas otras bibliotecas de ciencia de datos, incluida Pandas, se construyen sobre esta base. Su uso es crucial para el procesamiento de grandes vol√∫menes de datos y c√°lculos matem√°ticos avanzados."],"metadata":{"id":"wBsBwMFyy9RE"}},{"cell_type":"code","source":["# Montar la unidad\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"zVaTr8QyV-YV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verificar que los archivos csv se encuentren en la carpeta datasets\n","import os\n","os.listdir(\"/content/drive/MyDrive/GALARZA Marcelo Alejandro-ComisioÃÅn 25262-TPI Data Analytics/Datasets\")"],"metadata":{"id":"O4S0lYylWKYo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ruta_ventas = \"/content/drive/MyDrive/GALARZA Marcelo Alejandro-ComisioÃÅn 25262-TPI Data Analytics/Datasets/ventas.csv\"\n","ruta_clientes = \"/content/drive/MyDrive/GALARZA Marcelo Alejandro-ComisioÃÅn 25262-TPI Data Analytics/Datasets/clientes.csv\"\n","ruta_marketing = \"/content/drive/MyDrive/GALARZA Marcelo Alejandro-ComisioÃÅn 25262-TPI Data Analytics/Datasets/marketing.csv\"\n","\n","# Cargamos los CSV como DataFrames.\n","ventas = pd.read_csv(ruta_ventas)\n","clientes = pd.read_csv(ruta_clientes)\n","marketing = pd.read_csv(ruta_marketing)\n","\n","# Validamos formas para comprobar que se cargaron correctamente.\n","print(\"ventas.shape ->\", ventas.shape)\n","print(\"clientes.shape ->\", clientes.shape)\n","print(\"marketing.shape ->\", marketing.shape)\n","\n","# Mostramos las primeras filas de cada dataset para corroborar estructura de columnas.\n","display(ventas.head(3))\n","display(clientes.head(3))\n","display(marketing.head(3))"],"metadata":{"id":"kcxiADR1XMCs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2- Realizar un script b√°sico que calcule las ventas mensuales utilizando variables y operadores."],"metadata":{"id":"ZIVozj9PqU_R"}},{"cell_type":"markdown","source":["#### NO SE ENTREGA"],"metadata":{"id":"r6R-1OlqqaVy"}},{"cell_type":"markdown","source":["###3- Estructuras de Datos: Desarrollar un programa que almacene los datos de ventas (producto, precio, cantidad). Decidir si conviene utilizar diccionarios o listas."],"metadata":{"id":"XH1lBdP6qeC8"}},{"cell_type":"markdown","source":["#### NO SE ENTREGA"],"metadata":{"id":"8x5NT6fRqjMQ"}},{"cell_type":"markdown","source":["###4- Introducci√≥n a Pandas: realizar un an√°lisis exploratorio inicial de los DataFrames."],"metadata":{"id":"ncVSizdOqrMw"}},{"cell_type":"code","source":["def eda(df, nombre):\n","    print(f\"=== {nombre} ===\")\n","    print(\"shape:\", df.shape)\n","    print(\"columnas:\", list(df.columns))\n","    print(\"dtypes:\")\n","    print(df.dtypes)\n","    print(\"\\nNulos por columna:\")\n","    print(df.isna().sum())\n","    print(\"\\nPrimeras filas:\")\n","    display(df.head(5))\n","    print(\"\\nDescribe (num√©rico):\")\n","    display(df.describe(include='number'))\n","    print(\"-\"*100)"],"metadata":{"id":"anfd3o3fXl9K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eda(ventas, \"VENTAS (inicial)\")"],"metadata":{"id":"XoX2KhjzXpT7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eda(clientes, \"Clientes (inicial)\")"],"metadata":{"id":"-wpuMw5cXqUT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eda(marketing, \"MARKETING (inicial)\")"],"metadata":{"id":"F2vcGSM9Xroy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###5- Calidad de Datos: Identificar valores nulos y duplicados en los conjuntos de datos. Documentar el estado inicial de los datos."],"metadata":{"id":"-fazvIjkq2fY"}},{"cell_type":"code","source":["# ============================================\n","# üîç FUNCI√ìN DE CONTROL DE CALIDAD DE DATOS\n","# ============================================\n","# Esta funci√≥n analiza un DataFrame existente (df) y muestra:\n","# 1Ô∏è‚É£ La cantidad de valores nulos por columna.\n","# 2Ô∏è‚É£ El total de filas completamente duplicadas.\n","# 3Ô∏è‚É£ Si se especifica una columna clave, los valores m√°s repetidos de esa clave.\n","\n","def calidad(df, nombre, clave=None):\n","    \"\"\"\n","    Analiza la calidad del DataFrame:\n","      - Muestra cantidad de nulos por columna.\n","      - Cuenta filas duplicadas completas.\n","      - Si se indica una clave, muestra los valores duplicados m√°s frecuentes.\n","    Par√°metros:\n","      df: DataFrame de pandas que se analizar√°.\n","      nombre: texto descriptivo del DataFrame (ejemplo: 'VENTAS').\n","      clave: (opcional) nombre de la columna para buscar duplicados espec√≠ficos.\n","    \"\"\"\n","\n","    # -------------------------------------------------\n","    # Mostrar t√≠tulo descriptivo con el nombre del DF\n","    # -------------------------------------------------\n","    print(f\"### {nombre}\")\n","\n","    # -------------------------------------------------\n","    # Mostrar cantidad de valores nulos por columna\n","    # -------------------------------------------------\n","    # df.isna() devuelve un DataFrame booleano con True donde hay NaN.\n","    # .sum() cuenta los True (o sea, los nulos) por columna.\n","    # .to_frame(\"nulos\") convierte el resultado en un DataFrame con una columna llamada 'nulos'.\n","    display(df.isna().sum().to_frame(\"nulos\"))\n","\n","    # -------------------------------------------------\n","    # Contar filas duplicadas completas\n","    # -------------------------------------------------\n","    # df.duplicated(keep=False) marca como True todas las filas que tienen otra igual.\n","    # keep=False significa que marca todas las copias, no solo una.\n","    # .sum() cuenta cu√°ntas filas est√°n repetidas.\n","    dup_rows = df.duplicated(keep=False).sum()\n","    print(\"Filas duplicadas (exactas):\", dup_rows)\n","\n","    # -------------------------------------------------\n","    # Si se especific√≥ una columna clave v√°lida, analizar duplicados por esa columna\n","    # -------------------------------------------------\n","    # if clave analiza que clave no sea None\n","    # and (y)\n","    if clave and clave in df.columns:\n","    # clave in df.columns-- >que clave sea una columna existente dentro de las columnas del dataframe\n","    # si no le paso ninguna columna no va a querer encontrar duplicados por columna\n","    # y si me equivoco y le paso una columna que no existe en el dataframe, tampoco ingresara al if.\n","        # Contar cu√°ntas filas tienen valores repetidos en esa columna\n","        dup_key = df[clave].duplicated(keep=False).sum()\n","        print(f\"Duplicados por clave '{clave}':\", dup_key)\n","\n","        # Si existen duplicados, mostrar cu√°les son los valores m√°s repetidos\n","        if dup_key > 0:\n","            # Filtrar filas donde esa clave est√© duplicada\n","            # df[clave].duplicated(keep=False) devuelve True donde el valor se repite\n","            duplicados_ordenados = (\n","                df[df[clave].duplicated(keep=False)][clave]\n","                .value_counts()                # Cuenta cu√°ntas veces aparece cada valor\n","                .sort_values(ascending=False)   # Ordena de mayor a menor (m√°s duplicados arriba)\n","            )\n","\n","            print(\"\\nüîÅ Top valores duplicados m√°s frecuentes:\")\n","            # Mostrar solo los primeros 10 (los m√°s repetidos)\n","            display(duplicados_ordenados.head(10))\n","        else:\n","            print(f\"No se encontraron duplicados en la clave '{clave}'.\")\n","    else:\n","        # Si la clave no fue pasada o no existe en el DataFrame\n","        if clave:\n","            print(f\"La clave '{clave}' no existe en el DataFrame.\")\n","        else:\n","            print(\"No se indic√≥ una clave para analizar duplicados por columna.\")\n","#fin de def calidad"],"metadata":{"id":"2CkS-a4DZSxp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calidad(ventas, \"VENTAS\", clave=\"id_venta\")"],"metadata":{"id":"IQ6VUllFZFYg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calidad(clientes, \"CLIENTES\", clave=\"id_cliente\")"],"metadata":{"id":"AXQExe8gZgqB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calidad(marketing, \"MARKETING\", clave=\"id_campanha\")"],"metadata":{"id":"yXhBGGm4ZlPJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Etapa 2: Preprocesamiento y Limpieza de Datos (Clases 5 a 8)"],"metadata":{"id":"4NdTjTx7rP7o"}},{"cell_type":"markdown","source":["\n","**Limpieza del dataset**\n","- Eliminamos duplicados.\n","- Normalizamos **texto** en columnas `object` (trim + capitalizaci√≥n simple).\n","- Convertimos fechas a fechas reales\n","- Convertimos `precio` y `cantidad` a num√©ricos si existen.\n","- Guardamos CSV limpios.\n"],"metadata":{"id":"uzKoJc5BrjZw"}},{"cell_type":"markdown","source":["###1- Limpieza de Datos: Limpiar el conjunto de datos eliminando duplicados y caracteres no deseados. Documentar el proceso y los resultados."],"metadata":{"id":"6eln0ZaPrZCi"}},{"cell_type":"code","source":["# ============================================\n","# üßπ LIMPIEZA Y NORMALIZACI√ìN DE LOS DATASETS\n","# ============================================\n","# Se limpian y normalizan los DataFrames:\n","#   ventas, clientes, marketing\n","# ============================================\n","\n","# -------------------------------------------------\n","# 1Ô∏è‚É£ Crear copias independientes para no modificar los originales\n","# -------------------------------------------------\n","ventas_clean = ventas.copy()\n","clientes_clean = clientes.copy()\n","marketing_clean = marketing.copy()\n","\n","# -------------------------------------------------\n","# 2Ô∏è‚É£ Eliminar filas completamente duplicadas\n","# -------------------------------------------------\n","ventas_clean = ventas_clean.drop_duplicates()\n","clientes_clean = clientes_clean.drop_duplicates()\n","marketing_clean = marketing_clean.drop_duplicates()"],"metadata":{"id":"OnnUNK4aZpzk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"ventas_clean.shape ->\", ventas_clean.shape)\n","print(\"clientes_clean.shape ->\", clientes_clean.shape)\n","print(\"marketing_clean.shape ->\", marketing_clean.shape)"],"metadata":{"id":"fPVQsKZaZt5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calidad(ventas_clean, \"VENTAS CLEAN\", clave=\"id_venta\")"],"metadata":{"id":"j_IcZv9HZ35R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------------------------------------\n","# 3Ô∏è‚É£ Funci√≥n para limpiar texto en columnas tipo string\n","# -------------------------------------------------\n","def normalizar_texto(df):\n","    for col in df.select_dtypes(include=\"object\").columns:\n","        # Se agrupan las operaciones entre par√©ntesis () para escribirlas en varias l√≠neas\n","        # Python eval√∫a todo el bloque como una √∫nica expresi√≥n.\n","        df[col] = (\n","            df[col]\n","            .astype(str)                              # Convierte cualquier tipo a string\n","            # .astype(str)  ‚Üí convierte todo a texto; no tiene par√°metros adicionales.\n","            .str.strip()                               # Elimina espacios al inicio y final\n","            # .str.strip() no necesita argumentos; borra espacios en blanco por defecto.\n","            .str.replace(r\"[\\u200b\\t\\r\\n]\", \"\", regex=True)\n","            # .str.replace(patron, reemplazo, regex=True)\n","            #   patron: expresi√≥n regular que busca caracteres invisibles (\\u200b, tabulaciones, saltos)\n","            #   reemplazo: \"\"  ‚Üí los elimina\n","            #   regex=True indica que 'patron' es una expresi√≥n regular.\n","            .str.replace(\" +\", \" \", regex=True)\n","            # reemplaza \"uno o m√°s espacios consecutivos\" por un solo espacio\n","            .str.title()                               # Convierte a T√≠tulo: \"juan p√©rez\" ‚Üí \"Juan P√©rez\"\n","        )\n","        #df_transformado=df[col].astype(str)\n","        #df_transformado=df_transformado.str.strip()\n","        #df_transformado=df_transformado.str.replace(r\"[\\u200b\\t\\r\\n]\", \"\", regex=True)\n","        #df_transformado=df_transformado.str.replace(\" +\", \" \", regex=True)\n","        #df_transformado=df_transformado.str.title()\n","        #df[col]=df_transformado\n","\n","        #df[col] = df[col].astype(str).str.strip().str.replace(r\"[\\u200b\\t\\r\\n]\", \"\", regex=True).str.replace(\" +\", \" \", regex=True).str.title()\n","    return df\n"],"metadata":{"id":"WKBecaohZ_uC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------------------------------------\n","# Normalizar fechas\n","# -------------------------------------------------\n","# Si alguna columna contiene fechas (por ejemplo \"fecha\" o \"fechanotificacion\"),\n","# se intenta convertir a formato datetime de pandas.\n","# to_datetime intenta interpretar el formato y transforma valores inv√°lidos en NaT (Not a Time).\n","\n","for df in [ventas_clean, clientes_clean, marketing_clean]:\n","    for col in df.columns:\n","        if \"fecha\" in col.lower():  # detecta columnas con la palabra \"fecha\"\n","            df[col] = pd.to_datetime(df[col], errors=\"coerce\", dayfirst=True)\n","            # Par√°metros:\n","            #   errors=\"coerce\" ‚Üí convierte valores no v√°lidos en NaT (evita error)\n","            #   dayfirst=True   ‚Üí interpreta formatos tipo \"DD/MM/YYYY\" (formato latino)\n","#n"],"metadata":{"id":"7JRwMqEwaGe5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#NORMALIZO FECHAS DE DF DE VENTAS(ESTO TAMBIEN ESTA PERFECTO!!, es lo mismo de arriba, pero sabiendo los nombres de las fechas)\n","\n","ventas_clean[\"fecha_venta\"] = pd.to_datetime(ventas_clean[\"fecha_venta\"], errors=\"coerce\", dayfirst=True)"],"metadata":{"id":"miCAsttMaLuq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#NORMALIZO FECHAS DE DF DE MARKETING\n","\n","marketing_clean[\"fecha_inicio\"] = pd.to_datetime(marketing_clean[\"fecha_inicio\"], errors=\"coerce\", dayfirst=True)\n","marketing_clean[\"fecha_fin\"] = pd.to_datetime(marketing_clean[\"fecha_fin\"], errors=\"coerce\", dayfirst=True)"],"metadata":{"id":"BAOsZuKdaQ4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ventas_clean.dtypes)\n","print(clientes_clean.dtypes)\n","print(marketing_clean.dtypes)"],"metadata":{"id":"8sODLoEAaY4J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------------------------------------\n","#  Aplicar la normalizaci√≥n de texto\n","# -------------------------------------------------\n","ventas_clean = normalizar_texto(ventas_clean)\n","clientes_clean = normalizar_texto(clientes_clean)\n","marketing_clean = normalizar_texto(marketing_clean)"],"metadata":{"id":"pIz9Q3kNanNY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#mostramos los df luego de normalizar los textos para revisar que queden bien\n","print(ventas_clean.head(10))\n","print(clientes_clean.head(10))\n","print(marketing_clean.head(10))"],"metadata":{"id":"k8Hl22VlasRs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------------------------------------\n","# 6Ô∏è‚É£ Normalizar valores num√©ricos\n","# -------------------------------------------------\n","# üè∑Ô∏è Campo \"precio\"\n","if \"precio\" in ventas_clean.columns:\n","    # Se usa nuevamente agrupaci√≥n con () para encadenar m√©todos y mantener legibilidad\n","    ventas_clean[\"precio\"] = (\n","        ventas_clean[\"precio\"]\n","        .astype(str)                        # Convierte todo a texto\n","        .str.replace(\"$\", \"\", regex=False)  # Elimina el s√≠mbolo $\n","        #   \"$\" ‚Üí texto literal a reemplazar\n","        #   \"\"  ‚Üí nuevo valor (vac√≠o)\n","        #   regex=False ‚Üí interpreta \"$\" literalmente, no como expresi√≥n regular\n","        .str.replace(\",\", \"\", regex=False)  # Elimina comas de miles 1,000  1000\n","        .str.strip()                        # Quita espacios sobrantes\n","    )\n","    ventas_clean[\"precio\"] = pd.to_numeric(ventas_clean[\"precio\"], errors=\"coerce\")\n","    # pd.to_numeric convierte texto a n√∫mero (float o int)\n","    # Par√°metros:\n","    #   errors=\"coerce\" ‚Üí reemplaza valores no convertibles con NaN"],"metadata":{"id":"Xy2NpD9maxyq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ventas_clean.dtypes)"],"metadata":{"id":"FmRON4hTa1Yh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ventas_clean.columns)"],"metadata":{"id":"7IT7oTuCa5YA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# üßÆ Campo \"cantidad\"\n","if \"cantidad\" in ventas_clean.columns:\n","    ventas_clean[\"cantidad\"] = pd.to_numeric(\n","        ventas_clean[\"cantidad\"], errors=\"coerce\"\n","    ).astype(\"Int64\")\n","    # .astype(\"Int64\") usa el tipo entero de pandas que permite valores nulos (NaN)"],"metadata":{"id":"BKTcYVw8a-LQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ventas_clean.dtypes)"],"metadata":{"id":"YOOAye4cbHoA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------------------------------------\n","# 7Ô∏è‚É£ Guardar los DataFrames limpios como CSV\n","# -------------------------------------------------\n","#print(ventas_clean.head())\n","#print(clientes_clean.head())\n","#print(marketing_clean.head())\n","ventas_clean.info()\n","ventas_clean.to_csv(\"/content/drive/MyDrive/GALARZA Marcelo Alejandro-ComisioÃÅn 25262-TPI Data Analytics/Datasets/ventas.csv\", index=False)\n","clientes_clean.to_csv(\"/content/drive/MyDrive/GALARZA Marcelo Alejandro-ComisioÃÅn 25262-TPI Data Analytics/Datasets/clientes.csv\", index=False)\n","marketing_clean.to_csv(\"/content/drive/MyDrive/GALARZA Marcelo Alejandro-ComisioÃÅn 25262-TPI Data Analytics/Datasets/marketing.csv\", index=False)\n","\n","print(\"‚úÖ Archivos guardados: ventas_clean.csv, clientes_clean.csv, marketing_clean.csv\")"],"metadata":{"id":"gb_rCJaAbOZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ventas_clean.select_dtypes(include=\"object\").columns)"],"metadata":{"id":"fWDhM-_7bqP4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================\n","# üìä REPORTE GLOBAL DE CALIDAD DE DATOS\n","# ============================================\n","# Esta funci√≥n lee los tres DataFrames limpios (o los recibe en memoria)\n","# y muestra un resumen comparativo de nulos, duplicados y tipos de datos.\n","# ============================================\n","\n","def reporte_calidad_global(dfs, nombres):\n","    \"\"\"\n","    Crea un resumen de calidad de varios DataFrames.\n","\n","    Par√°metros:\n","      dfs: lista de DataFrames (por ejemplo [ventas_clean, clientes_clean, marketing_clean])\n","      nombres: lista de nombres correspondientes ([\"VENTAS\", \"CLIENTES\", \"MARKETING\"])\n","    \"\"\"\n","    resumen = []\n","    #zip-->es una funci√≥n incorporada de Python que une elementos de dos (o m√°s) iterables\n","    # ‚Äîpor ejemplo, listas, tuplas o cualquier objeto iterable‚Äî en pares ordenados.\n","    for df, nombre in zip(dfs, nombres):\n","        nulos = df.isna().sum().sum()                    # Total de valores nulos, no por columnas sino total, por eso el doble sum\n","        duplicados = df.duplicated(keep=False).sum()     # Total de filas duplicadas\n","        columnas = len(df.columns)                       # Cantidad de columnas\n","        filas = len(df)                                  # Cantidad de registros\n","\n","        resumen.append({\n","            \"Dataset\": nombre,\n","            \"Filas\": filas,\n","            \"Columnas\": columnas,\n","            \"Nulos totales\": nulos,\n","            \"Duplicados\": duplicados,\n","        })\n","\n","    reporte = pd.DataFrame(resumen)\n","    #display(reporte)\n","    return reporte\n","\n","# ============================================\n","# ‚úÖ Ejemplo de uso\n","# ============================================"],"metadata":{"id":"GM4_FVg-by5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(reporte_calidad_global([ventas, clientes, marketing], [\"VENTAS Original\", \"CLIENTES Original\", \"MARKETING Original\"]))\n","print(reporte_calidad_global([ventas_clean, clientes_clean, marketing_clean],[\"VENTAS Copia   \", \"CLIENTES Copia   \", \"MARKETING Copia   \"]))"],"metadata":{"id":"BClD_dnBeurs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##2- Transformaci√≥n de Datos: Aplicar filtros y transformaciones para crear una tabla de ventas que muestre solo los productos con alto rendimiento."],"metadata":{"id":"qLF1183ctKiZ"}},{"cell_type":"markdown","source":["###üü¶ Transformaci√≥n de datos (filtrar ‚Äúalto rendimiento‚Äù)\n","\n","\n","### Objetivo: construir una tabla de rendimiento por producto y quedarnos s√≥lo con los productos de alto rendimiento.\n","\n","Conceptos clave:\n","\n","<h3>Transformaci√≥n de datos:</h3> son operaciones que crean/derivan nuevas columnas (por ejemplo ingreso = precio * cantidad), normalizan formatos (texto/fechas/n√∫meros) o filtran filas seg√∫n un criterio.\n","\n","<h3>M√©trica de ingreso:</h3> para ventas, una m√©trica t√≠pica es ingreso por registro = precio * cantidad. Luego podemos agregar por producto (sumar ingresos y unidades) para medir rendimiento total por producto.\n","\n","<h3>Agregaci√≥n:</h3> es resumir muchas filas en pocas, aplicando funciones como sum(), mean(), count() agrupando por una clave (ej., producto).\n","Ej.: ‚Äúingreso total por producto‚Äù = suma de todos los ingresos de ese producto.\n","\n","<h3>Percentil:</h3> el percentil 80 (P80) es un valor tal que el 80% de los datos est√°n por debajo o igual a ese valor y el 20% restante por encima.\n","\n","Si ingreso_total P80 = 120.000, significa que el 80% de los productos tienen ingreso_total ‚â§ 120.000 y el 20% ‚â• 120.000.\n","\n","<h3>Alto rendimiento:</h3> aqu√≠ lo definimos como top 20% de productos seg√∫n ingreso_total (>= P80). Es un criterio com√∫n cuando no hay umbrales de negocio expl√≠citos.\n","Alternativas v√°lidas: top-K (p. ej. top 50 productos), percentil 75 (P75) o un umbral fijo de negocio (p. ej., ‚Äú>= $100.000/mes‚Äù), o score estandarizado (z-score).\n","\n","<h3>Plan paso a paso:</h3>\n","\n","Detectar la columna de producto (tolerando distintos nombres: producto, id_producto, sku, articulo‚Ä¶).\n","\n","Calcular ingreso por registro = precio * cantidad.\n","\n","Agregar por producto para obtener m√©tricas (ingreso_total, unidades, precio_promedio, registros).\n","\n","Calcular P80 con quantile(q=0.80).\n","\n","Filtrar productos con ingreso_total >= P80.\n","\n","Ordenar de mayor a menor."],"metadata":{"id":"NNyGiKpHtpE4"}},{"cell_type":"code","source":["# ============================================\n","# TRANSFORMACI√ìN: productos de alto rendimiento\n","# ============================================\n","# Objetivo:\n","# - Detectar los productos con mejor desempe√±o econ√≥mico (top 20% por ingreso total).\n","# - Aplicar transformaci√≥n: calcular ingreso, agregar por producto y filtrar.\n","# ============================================\n","\n","def encontrar_columna(df, candidatos):\n","    \"\"\"\n","    Busca la primera columna cuyo nombre contenga alguno de los patrones dados.\n","    - df: DataFrame de pandas.\n","    - candidatos: lista de patrones (min√∫sculas).\n","    \"\"\"\n","    # Recorremos todas las columnas del DataFrame\n","    for c in df.columns:\n","\n","        # Convertimos el nombre de la columna a min√∫sculas\n","        # Esto se hace para comparar sin importar si est√° escrito con may√∫sculas o min√∫sculas\n","        nombre = c.lower()\n","\n","        # Verificamos si alguna palabra (patr√≥n) de la lista 'candidatos'\n","        # est√° contenida dentro del nombre de la columna\n","        # 'any()' devuelve True apenas encuentra una coincidencia\n","        if any(p in nombre for p in candidatos):\n","            # Si encontramos una coincidencia, devolvemos el nombre original de la columna\n","            return c\n","\n","    # Si termina el bucle y no se encontr√≥ ninguna coincidencia, devolvemos None\n","    return None"],"metadata":{"id":"Q-gFkrpVe1a5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# 1Ô∏è‚É£ Detectar la columna de producto\n","prod_col = encontrar_columna(ventas_clean, [\"producto\", \"id_producto\", \"sku\", \"articulo\", \"art√≠culo\"])\n","if prod_col is None:\n","    raise ValueError(\"No se encontr√≥ columna de producto. Renombr√° una columna a 'producto' o similar.\")\n","\n","print(prod_col)"],"metadata":{"id":"GiDGNee5fFHh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2Ô∏è‚É£ Calcular ingreso por registro = precio * cantidad\n","#() es para escribir en varias filas\n","ventas_perf = (\n","    ventas_clean\n","    .assign(\n","        ingreso = ventas_clean[\"precio\"] * ventas_clean[\"cantidad\"]\n","        # assign(**nuevas_col): crea nuevas columnas y devuelve una copia del DF.\n","        # Alternativa: ventas_clean[\"ingreso\"] = ventas_clean[\"precio\"] * ventas_clean[\"cantidad\"]\n","    )\n",")\n","#esta linea comentada es igual que la linea multiple de arriba\n","#ventas_perf = ventas_clean.assign(ingreso = ventas_clean[\"precio\"] * ventas_clean[\"cantidad\"])\n","#esta otra linea agrega a ventas_clean una columna nueva ingreso y le asigna precio*cantidad\n","#ventas_clean[\"ingreso\"] = ventas_clean[\"precio\"] * ventas_clean[\"cantidad\"]"],"metadata":{"id":"B4AeMVo4fQVV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3Ô∏è‚É£ Agregar m√©tricas por producto\n","resumen_prod = (\n","    ventas_perf\n","    # 1) Agrupamos el DataFrame por una o varias columnas clave\n","    .groupby(\n","        by=prod_col,    # Columna (str) o lista de columnas (list[str]) que define los grupos.\n","        dropna=False,   # False ‚Üí NO descarta filas donde la clave de grupo tenga NaN; crea un grupo para NaN.\n","        as_index=False, # False ‚Üí las columnas de agrupaci√≥n quedan como columnas normales (no pasan al √≠ndice).\n","        observed=False  # Solo aplica si 'prod_col' es Categorical:\n","                        #   False ‚Üí incluye categor√≠as NO observadas (posibles pero sin filas);\n","                        #   True  ‚Üí solo categor√≠as que aparecen en los datos (m√°s r√°pido y ‚Äúcompacto‚Äù).\n","    )\n","    # 2) Agregamos (resumimos) columnas num√©ricas por cada grupo\n","    .agg(\n","        ingreso_total=('ingreso', 'sum'),   # Suma de 'ingreso' por grupo (skipna=True por defecto).\n","        unidades=('cantidad', 'sum'),       # Suma de 'cantidad' por grupo.\n","        precio_promedio=('precio', 'mean'), # Promedio simple de 'precio' por grupo (ignora NaN).\n","        registros=('ingreso', 'size')       # N√∫mero de filas en el grupo (cuenta TODO, incluso NaN).\n","    )\n",")\n","#se puede escribir asi:\n","resumen_prod = ventas_perf.groupby(by=prod_col).agg(ingreso_total=('ingreso', 'sum'), unidades=('cantidad', 'sum'), precio_promedio=('precio', 'mean'), registros=('ingreso', 'size'))"],"metadata":{"id":"JzVNEFTkfU_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(resumen_prod.head(60))\n","#ordenar resumen_prod por el mayor ingreso_total, y redondear precio_promedio a 2 decimales redondeado"],"metadata":{"id":"-d2xqo05fer7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4Ô∏è‚É£ Calcular percentil 80 de ingreso_total\n","# --------------------------------------------------------\n","# La funci√≥n quantile() nos permite obtener el valor de un percentil.\n","# En este caso, queremos saber el ingreso que separa al 80% de los productos\n","# con menores ingresos del 20% con mayores ingresos.\n","\n","p80_ingreso = resumen_prod[\"ingreso_total\"].quantile(\n","    q=0.80,                # q indica el percentil deseado (0.80 = 80% de los datos por debajo)\n","    interpolation=\"linear\" # si el percentil no coincide exactamente con un valor real del dataset,\n","                           # 'linear' interpola entre los dos valores vecinos.\n","                           # Ejemplo: si el 80% cae entre 4000 y 5000,\n","                           # calcula un valor proporcional, por ejemplo 4200.\n","                           # Otros m√©todos posibles:\n","                           #  - 'lower': toma el menor de los dos valores (4000)\n","                           #  - 'higher': toma el mayor (5000)\n","                           #  - 'nearest': el m√°s cercano al percentil\n","                           #  - 'midpoint': el punto medio exacto (4500)\n",")\n","\n","# En resumen:\n","# - quantile calcula el valor l√≠mite de un percentil.\n","# - q define qu√© percentil queremos.\n","# - interpolation define c√≥mo se calcula cuando el valor no est√° exactamente en los datos.\n","# El resultado (p80_ingreso) es el ingreso total que marca el l√≠mite superior del 80% de los productos.\n","\n","\n","# 5Ô∏è‚É£ Filtrar los productos \"de alto rendimiento\" y ordenarlos\n","# -------------------------------------------------------------------\n","# Contexto: `resumen_prod` es un DataFrame con m√©tricas por producto,\n","# y `p80_ingreso` es el percentil 80 de la columna \"ingreso_total\".\n","# Objetivo: quedarnos con los productos cuyo ingreso_total est√° en el 20% superior\n","# (ingreso_total >= p80_ingreso) y luego ordenarlos de mayor a menor por ingreso y unidades.\n","# en una sola fila\n","#ventas_top = resumen_prod.query(\"ingreso_total >= @p80_ingreso\",engine=\"python\").sort_values(by=[\"ingreso_total\", \"unidades\"], ascending=[False, False], na_position=\"last\", ignore_index=True\n","ventas_top = (\n","    resumen_prod\n","    # ---------------------------------------------------------------\n","    # .query(expr, *, inplace=False, engine='python'|'numexpr')\n","    #   - Aplica un filtro usando una expresi√≥n estilo SQL-simple.\n","    #   - `expr` es un string que se eval√∫a sobre los nombres de las columnas.\n","    #   - Para usar variables de Python (no columnas), se antepone '@' (ej.: @p80_ingreso).\n","    #   - NaN en comparaciones (>, >=, ==, etc.) se comportan como False ‚Üí esas filas no pasan el filtro.\n","    #   - engine='python': interpreta la expresi√≥n con Python puro (compatible siempre).\n","    #   - engine='numexpr': si est√° instalado, acelera operaciones num√©ricas vectorizadas.\n","    #   - inplace: False (por defecto) devuelve un DF nuevo; True modifica el DF original (menos recomendado en cadenas).\n","    .query(\n","        \"ingreso_total >= @p80_ingreso\",  # expr: filtra filas donde ingreso_total es al menos el umbral del P80\n","        engine=\"python\"                   # motor de evaluaci√≥n (usar 'numexpr' si lo ten√©s y quer√©s performance)\n","        # Notas de sintaxis de `expr`:\n","        #   ‚Ä¢ Operadores l√≥gicos: and / or / not   (tambi√©n valen &, |, ~ con par√©ntesis).\n","        #   ‚Ä¢ Strings deben ir entre comillas: canal == 'Online'\n","        #   ‚Ä¢ Columnas con espacios o caracteres raros: usar `backticks`, ej.: `nombre producto` == 'X'\n","        #   ‚Ä¢ Ejemplos:\n","        #       \"ingreso_total >= @p80_ingreso and unidades >= 10\"\n","        #       \"`nombre producto`.str.contains('Promo')\"\n","        #       \"precio_promedio.between(1000, 3000, inclusive='both')\"\n","    )\n","    # ---------------------------------------------------------------\n","    # .sort_values(by, axis=0, ascending=True|[...], inplace=False,\n","    #              kind='quicksort'|'mergesort'|'heapsort'|'stable',\n","    #              na_position='last'|'first', ignore_index=False, key=None)\n","    #   - Ordena por una o varias columnas.\n","    #   - `by`: str o lista de str con las columnas a ordenar.\n","    #   - `ascending`: bool o lista de bool (una por cada columna en `by`).\n","    #   - `na_position`: d√≥nde ubicar NaN ('last' o 'first').\n","    #   - `ignore_index`: si True, reasigna el √≠ndice 0..n-1 en el resultado.\n","    #   - `kind`: algoritmo de ordenamiento (mergesort es estable si necesit√°s preservar empates).\n","    #   - `key`: funci√≥n que transforma los valores antes de ordenar (p. ej., key=lambda s: s.str.normalize(...)).\n","    .sort_values(\n","        by=[\"ingreso_total\", \"unidades\"],  # primero ordena por ingreso_total, luego desempata por unidades\n","        ascending=[False, False],          # ambos en orden descendente (mayor ‚Üí menor)\n","        na_position=\"last\",                # coloca NaN al final (√∫til si alguna m√©trica qued√≥ en NaN)\n","        ignore_index=False                  # reindexa el resultado secuencialmente (0..n-1)\n","        # Variantes √∫tiles:\n","        #   ‚Ä¢ ascending=True                 # orden ascendente\n","        #   ‚Ä¢ ascending=[False, True]        # primero desc, luego asc para el segundo criterio\n","        #   ‚Ä¢ kind='mergesort'               # orden estable (respeta el orden de aparici√≥n en empates)\n","        #   ‚Ä¢ key=lambda s: s.str.lower()    # ordenar texto sin distinci√≥n de may√∫sculas/min√∫sculas\n","    )\n",")\n","\n","# Resultado:\n","# `ventas_top` contiene solo los productos cuyo ingreso_total >= p80_ingreso,\n","# ordenados de mayor a menor por ingreso_total y, ante empates, por unidades.\n","\n","\n","# 6Ô∏è‚É£ Mostrar resultados\n","print(f\"Columna de producto detectada: {prod_col}\")\n","print(f\"Umbral (percentil 80) de ingreso_total: {float(p80_ingreso):,.2f}\")\n","print(\"‚úÖ Productos de ALTO RENDIMIENTO (top 20% por ingreso):\")\n","display(ventas_top.head(60))"],"metadata":{"id":"HZIXTa6mfpaB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###3- Agregaci√≥n: Resumir las ventas por categor√≠a de producto y analizar los ingresos generados."],"metadata":{"id":"fgrp_eAAug8h"}},{"cell_type":"markdown","source":["###Agregaci√≥n (resumen por categor√≠a y an√°lisis de ingresos)\n","### Conceptos y plan\n","\n","Objetivo: construir un resumen por categor√≠a de producto con m√©tricas √∫tiles (ingreso total, unidades, cantidad de ventas, ticket promedio).\n","\n","Conceptos clave:\n","\n","Agregaci√≥n: operaci√≥n que resume muchas filas en menos filas, aplicando funciones (sum, mean, count, etc.) despu√©s de agrupar por una clave (aqu√≠, la categor√≠a).\n","\n","Categor√≠a de producto: atributo que agrupa productos similares (ej., ‚ÄúElectr√≥nica‚Äù, ‚ÄúHogar‚Äù). Puede llamarse categoria, rubro, etc.\n","\n","Ticket promedio por venta: ingreso_total / ventas (d√≥nde ventas es el conteo de filas en esa categor√≠a). Indica el importe medio facturado por cada transacci√≥n/registro en la categor√≠a.\n","\n","Nota: esto no es el ‚Äúprecio promedio‚Äù del producto; ese ya se calcula con mean sobre precio.\n","\n","Consideraciones: outliers pueden distorsionar promedios; a veces conviene mirar tambi√©n la mediana (median).\n","\n","Plan paso a paso:\n","\n","Detectar la columna de categor√≠a.\n","\n","Asegurar columna ingreso (si no existe, crearla).\n","\n","groupby(categor√≠a).agg(...) para obtener m√©tricas.\n","\n","Ordenar por ingreso_total.\n","\n","Calcular ticket_promedio_por_venta."],"metadata":{"id":"3YytR28MvGpx"}},{"cell_type":"code","source":["# ============================================\n","# 8) AGREGACI√ìN: resumen por categor√≠a\n","# ============================================\n","# Requisitos:\n","# - 'ventas_clean' tiene columnas 'precio', 'cantidad' y alguna columna \"categor√≠a\".\n","# ============================================\n","\n","# -- Helper para detectar la columna de categor√≠a --\n","def encontrar_columna(df, candidatos):\n","    \"\"\"\n","    df: DataFrame de pandas que queremos inspeccionar.\n","    candidatos: iterable de strings con patrones posibles para el nombre de la columna\n","                (por ejemplo: [\"categoria\", \"cat\", \"segmento\"]).\n","    Devuelve:\n","      - El nombre de la PRIMERA columna cuyo nombre contenga alguno de los patrones (b√∫squeda por subcadena,\n","        sin distinguir may√∫sculas/min√∫sculas).\n","      - None si no encuentra coincidencias.\n","    \"\"\"\n","\n","    # Recorremos todos los nombres de columnas del DataFrame (df.columns es un Index con esos nombres).\n","    for c in df.columns:\n","\n","        # any(...) devuelve True si AL MENOS UNO de los elementos del generador interno es True.\n","        # Generador: (p in c.lower() for p in candidatos)\n","        #   - c.lower(): pasamos el nombre de la columna a min√∫sculas para comparar sin importar may√∫sculas/min√∫sculas.\n","        #   - p in c.lower(): chequea si el patr√≥n 'p' aparece como SUBCADENA dentro del nombre de la columna.\n","        #   - Se eval√∫a para cada 'p' en 'candidatos'.\n","        if any(p in c.lower() for p in candidatos):\n","           # Si encontramos una coincidencia, devolvemos inmediatamente el nombre ORIGINAL de la columna.\n","            return c\n","    # Si terminamos el bucle sin encontrar coincidencias, devolvemos None para indicar \"no encontrada\".\n","    return None\n","\n","# Nota did√°ctica:\n","# - Esto hace coincidencia por SUBCADENA (ej.: \"prod\" matchea \"producto_sku\").\n","# - Si quer√©s coincidencia EXACTA, us√° igualdad (c.lower() == p) o expresiones regulares.\n","# - Si tus datos pueden tener acentos/espacios raros, pod√©s normalizar:\n","#     import unicodedata, re\n","#     def norm(s): return re.sub(r'\\s+', ' ', ''.join(ch for ch in unicodedata.normalize('NFKD', s)\n","#                                    if not unicodedata.combining(ch))).strip().lower()\n","\n","\n","# 1) Detectar columna de categor√≠a (acepta variantes)\n","cat_col = encontrar_columna(ventas_clean, [\"categoria\", \"categor√≠a\", \"categoria_producto\", \"rubro\"])\n","if cat_col is None:\n","    raise ValueError(\"No se encontr√≥ columna de categor√≠a (por ej. 'categoria' o 'rubro').\")\n","\n","# 2) Asegurar columna 'ingreso' (si no existe, crearla)\n","if \"ingreso\" not in ventas_clean.columns:\n","    ventas_cat = ventas_clean.assign(ingreso = ventas_clean[\"precio\"] * ventas_clean[\"cantidad\"])\n","else:\n","    ventas_cat = ventas_clean.copy()\n","\n","# 3) Agregaci√≥n por categor√≠a con groupby + agg\n","resumen_cat = (\n","    ventas_cat\n","    .groupby(\n","        by=cat_col,      # Puede ser string o lista de strings si quisi√©ramos agrupar por varias columnas.\n","        dropna=False,    # Mantener grupo NaN (si hay filas sin categor√≠a).\n","        as_index=False   # Dejar la categor√≠a como columna normal (y no como √≠ndice).\n","        # observed: si cat_col es 'category' y queremos mostrar solo categor√≠as presentes ‚Üí True.\n","    )\n","    .agg(\n","        ingreso_total=('ingreso', 'sum'),   # Suma total de ingresos por categor√≠a.\n","        unidades=('cantidad', 'sum'),       # Unidades totales vendidas en la categor√≠a.\n","        ventas=('ingreso', 'size'),         # Cantidad de registros/filas (ventas) en la categor√≠a.\n","        precio_promedio=('precio', 'mean')  # Precio promedio observado en la categor√≠a.\n","        # Otras funciones √∫tiles: 'median','max','min','std','var','nunique'...\n","    )\n","    .sort_values(\n","        by='ingreso_total', # Ordenar por ingreso total\n","        ascending=False,    # Descendente: mayores arriba\n","        na_position='last', # NaN al final\n","        ignore_index=True   # Reindexar desde 0\n","    )\n",")\n","\n","# 4) Ticket promedio por venta = ingreso_total / ventas\n","resumen_cat = resumen_cat.assign(\n","    ticket_promedio_por_venta = resumen_cat['ingreso_total'] / resumen_cat['ventas']\n","    # assign: crea/reescribe columnas. Alternativa: resumen_cat['ticket_promedio_por_venta'] = ...\n",")\n","\n","print(\"Columna de categor√≠a detectada:\", cat_col)\n","print(\"Resumen por categor√≠a (ordenado por ingreso_total):\")\n","display(resumen_cat.head(20))"],"metadata":{"id":"NZ6gOHUqvQ_6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###4- Integraci√≥n de Datos: Combinar los sets de datos de ventas y marketing para obtener una visi√≥n m√°s amplia de las tendencias."],"metadata":{"id":"UDh4Lgvrup6T"}},{"cell_type":"code","source":["# ============================================\n","# 9) INTEGRACI√ìN SIMPLE: combinar ventas y marketing\n","# ============================================\n","# Qu√© hace:\n","# - Busca una clave com√∫n sencilla para unir (por nombre t√≠pico).\n","# - Si no la encuentra, te deja dos variables para definirla a mano.\n","# - Calcula la cardinalidad real (1:1, 1:m, m:1, m:m) y la valida en el merge.\n","# - Hace un LEFT JOIN (conserva todas las ventas).\n","# - Si hay 'campa√±a'/'canal', resume ingresos por esas columnas.\n","# ============================================\n","\n","\n","# ---------------------------\n","# 1) Intento SIMPLE de detectar una clave com√∫n\n","# ---------------------------\n","claves_tentativas = [\n","    \"id_cliente\", \"cliente\", \"email\",\n","    \"id_campa√±a\", \"id_campana\", \"id_campanha\",\n","    \"sku\", \"id_producto\", \"producto\"\n","]\n","\n","# Busca la primera clave que exista con el mismo nombre en ambos DataFrames\n","clave_comun = next(\n","    (k for k in claves_tentativas if k in ventas_clean.columns and k in marketing_clean.columns),\n","    None\n",")\n","\n","# ---------------------------\n","# 2) Si NO hay clave exactamente igual en ambos, pedimos definir a mano\n","#    (esto NO corta el flujo: imprime gu√≠a y sigue si las completas)\n","# ---------------------------\n","# üëá Cambi√° estos nombres si tus columnas se llaman distinto en cada DF:\n","clave_ventas = None   # ej.: \"id_cliente\" (en ventas_clean)\n","clave_marketing = None  # ej.: \"cliente_id\" (en marketing_clean)\n","\n","# Si el usuario NO defini√≥ manualmente y TAMPOCO hay clave com√∫n, emitimos gu√≠a y salimos limpio\n","if clave_comun is None and (clave_ventas is None or clave_marketing is None):\n","    print(\"‚ùå No se encontr√≥ una clave com√∫n por nombre.\")\n","    print(\"üëâ Opciones:\")\n","    print(\"   a) Renombr√° una columna para que coincida en ambos DataFrames (ej.: 'id_cliente').\")\n","    print(\"   b) Defin√≠ manualmente las variables 'clave_ventas' y 'clave_marketing' m√°s arriba.\")\n","    print(\"      Ejemplo: clave_ventas='id_cliente'  |  clave_marketing='cliente_id'\")\n","    # Evitamos romper el notebook\n","else:\n","    # ---------------------------\n","    # 3) Determinar las columnas de uni√≥n y calcular cardinalidad REAL\n","    # ---------------------------\n","    if clave_comun is not None:\n","        # Caso simple: misma columna en ambos\n","        left_on = [clave_comun]\n","        right_on = [clave_comun]\n","        clave_label = clave_comun\n","    else:\n","        # Caso manual: columnas diferentes\n","        left_on = [clave_ventas]\n","        right_on = [clave_marketing]\n","        clave_label = f\"{clave_ventas} (ventas) ‚Üî {clave_marketing} (marketing)\"\n","\n","    # Funci√≥n de ayuda: ¬øhay duplicados en la(s) clave(s)?\n","    def hay_duplicados(df, cols):\n","        # cols puede tener 1 o m√°s columnas (clave compuesta)\n","        return df.duplicated(subset=cols, keep=False).any()\n","\n","    # Detectar cardinalidad:\n","    # - Si ventas no duplica clave y marketing s√≠ ‚Üí 1:m\n","    # - Si ventas s√≠ duplica y marketing no ‚Üí m:1\n","    # - Si ninguno duplica ‚Üí 1:1\n","    # - Si ambos duplican ‚Üí m:m\n","    dup_left = hay_duplicados(ventas_clean, left_on)\n","    dup_right = hay_duplicados(marketing_clean, right_on)\n","\n","    if not dup_left and not dup_right:\n","        validate_card = \"1:1\"\n","    elif not dup_left and dup_right:\n","        validate_card = \"1:m\"\n","    elif dup_left and not dup_right:\n","        validate_card = \"m:1\"\n","    else:\n","        validate_card = \"m:m\"\n","\n","    print(\"üîë Clave de uni√≥n:\", clave_label)\n","    print(\"üìê Cardinalidad detectada:\", validate_card)\n","\n","    # ---------------------------\n","    # 4) Hacer el MERGE (LEFT JOIN)\n","    # ---------------------------\n","    ventas_marketing = pd.merge(\n","        left=ventas_clean,      # DataFrame izquierdo: base principal (ventas)\n","        right=marketing_clean,  # DataFrame derecho: datos de marketing a anexar\n","        how=\"left\",             # how: 'left' (todas ventas), 'inner', 'outer', 'right'\n","        left_on=left_on,        # columnas de uni√≥n en 'left' (lista)\n","        right_on=right_on,      # columnas de uni√≥n en 'right' (lista)\n","        # on=...               # (alternativa si la columna tiene EXACTAMENTE el mismo nombre en ambos; excluyente con left_on/right_on)\n","        sort=False,             # sort: True ordena por clave tras el merge; False suele ser m√°s r√°pido\n","        suffixes=(\"_ven\", \"_mkt\"),  # sufijos para columnas con el mismo nombre en ambos DF\n","        copy=True,              # copy: True asegura copia (seguro); False puede ahorrar memoria\n","        indicator=True,         # indicator: agrega columna '_merge' con 'left_only'|'right_only'|'both'\n","        validate=validate_card  # validate: '1:1'|'1:m'|'m:1'|'m:m' ‚Üí lanza error si no se cumple\n","    )\n","\n","    # Diagn√≥stico b√°sico del resultado\n","    print(\"\\nüìã Origen de filas seg√∫n '_merge':\")\n","    display(ventas_marketing['_merge'].value_counts(dropna=False).to_frame('conteo'))\n","\n","    print(\"\\nüëÄ Primeras filas del DataFrame unificado:\")\n","    display(ventas_marketing.head())\n","\n","    # ---------------------------\n","    # 5) Resumen por CAMPA√ëA / CANAL (si existen esas columnas)\n","    # ---------------------------\n","    # Asegurar 'ingreso' = precio * cantidad si no existe\n","    vm = ventas_marketing.copy()\n","    if \"ingreso\" not in vm.columns and {\"precio\", \"cantidad\"}.issubset(vm.columns):\n","        vm = vm.assign(ingreso = vm[\"precio\"] * vm[\"cantidad\"])\n","\n","    # Detectar posibles columnas de campa√±a/canal por nombres comunes\n","    def hallar_col(df, patrones):\n","        for c in df.columns:\n","            if any(p in c.lower() for p in patrones):\n","                return c\n","        return None\n","\n","    camp_col  = hallar_col(vm, [\"campa√±a\", \"campana\", \"id_campa√±a\", \"id_campana\", \"id_campanha\", \"campaign\"])\n","    canal_col = hallar_col(vm, [\"canal\", \"utm_source\", \"fuente\", \"source\"])\n","\n","    if camp_col and \"ingreso\" in vm.columns:\n","        resumen_camp = (\n","            vm.groupby(by=camp_col, dropna=False, as_index=False)  # groupby: agrupa por campa√±a\n","              .agg(\n","                  ingreso_total=('ingreso', 'sum'),  # sum: suma de ingresos por campa√±a\n","                  ventas=('ingreso', 'size')         # size: cantidad de filas (ventas) por campa√±a\n","              )\n","              .sort_values(by='ingreso_total', ascending=False, na_position='last', ignore_index=True)\n","        )\n","        print(f\"\\nüí° Ingreso total por campa√±a ({camp_col}):\")\n","        display(resumen_camp.head(20))\n","    else:\n","        print(\"\\n‚ÑπÔ∏è No se encontr√≥ columna de campa√±a o no est√° 'ingreso' para resumir.\")\n","\n","    if canal_col and \"ingreso\" in vm.columns:\n","        resumen_canal = (\n","            vm.groupby(by=canal_col, dropna=False, as_index=False)\n","              .agg(\n","                  ingreso_total=('ingreso', 'sum'),\n","                  ventas=('ingreso', 'size')\n","              )\n","              .sort_values(by='ingreso_total', ascending=False, na_position='last', ignore_index=True)\n","        )\n","        print(f\"\\nüí° Ingreso total por canal ({canal_col}):\")\n","        display(resumen_canal.head(20))\n","    else:\n","        print(\"‚ÑπÔ∏è No se encontr√≥ columna de canal o no est√° 'ingreso' para resumir.\")\n"],"metadata":{"id":"RmtBNvTsgZMB"},"execution_count":null,"outputs":[]}]}